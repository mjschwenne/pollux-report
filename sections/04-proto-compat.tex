\section{Protobuf Compatibility Definitions}

\begin{definition}[Encoding Field]
	An encoding field is a tuple $(id, tag, value)$ which encodes the field
	number, tag and value of one field of a proto descriptor.
\end{definition}

Just like how the message descriptor is a sequence of field descriptors, the
encoding type of a message is an ordered list of encoding fields.
\\
\begin{definition}[Field Compatibility]
	For fields $f_1 = (id_1, tag_1, v_1)$ and $f_2 = (id_2, tag_2, v_2)$, $f_2$
	with descriptor $d_2$ is a compatible update to $f_1$ with descriptor $d_1$ if
	$id_1 = id_2$ and for all values $v_1$, $serialize_{d_1}\ f_1 = bs$ and there
	exists a $v_2$ such that $parse_{d_2}\ bs = v_2$ and $v_1 \prec v_2$ according to
	some relation $\prec$.
\end{definition}

An example value relation is given in Section~\ref{sec:val-rel}.
\\
\begin{definition}[Message Compatibility]
	A protobuf message descriptor $d_2$ is a compatible update to $d_1$ if every
	field in $d_1$ has a compatible field in $d_2$.
\end{definition}

Formally speaking, the message compatibility relation ($\preceq$) is given in
Section~\ref{sec:comp-rel}.
\\
\begin{definition}[Tag Function]
  The tag function $tag : \text{Type} \rightarrow \text{Tag}$ maps the \texttt{proto}
  level type to the corresponding tag as listed in Table~\ref{tab:tags}.
\end{definition}

It is also important to understand the default values of each protobuf
type. When a field is serialized with the default value or not set in the
message, the parser places the default value in the resulting struct. The
primary difference between an implicit field and an optional field is that the
optional field can differentiate between the serialized field being omitted from
the message or being present, but having the default value.
\\
\begin{definition}[Default Function]
  The default function
  $default: (t:\text{proto type}) \rightarrow \llbracket t \rrbracket$ returns the default
  value for each type.
  
  \[ default(t) = \left\{ 
    \begin{array}{l@{\quad:\quad}l}
      0 & t \in \left\{\begin{array}{c}
        \mathtt{int32}, \mathtt{int64}, \mathtt{uint32},
        \mathtt{uint64}, \mathtt{sint32}, \mathtt{sint64}, \\ \mathtt{fixed32},
        \mathtt{fixed64}, \mathtt{sfixed32}, \mathtt{sfixed64}, \mathtt{enum}
      \end{array}\right\} \\
      \mathtt{false} & t \text{ is } \mathtt{bool} \\
      ``" & t \text{ is } \mathtt{string} \\
      % 0 width space needed so that the brackets don't parse as a distance to
      % space out the elements of the array... for some unknown reason.
      \hspace{0pt}[\;] & t \text{ is } \mathtt{bytes}
    \end{array}\right.
  \]
\end{definition}

\section{Protobuf Compatibility Relations}~\label{sec:comp-rel}

Compatibility between protobuf entities is defined with a series of
relations. The first and most self-contained relation is the value relation,
which relates two values at the specification level if serializing just a value
(such as a variable width integer) and then parsing it to a different protobuf
type would lead to a different value. After that is the protobuf type relation,
which relates two protobuf type is any value of the first type is related to
some value of the second type in the value relation. Since protobuf field and
message definitions will not have concrete values associated with them, the type
relation can be used in place of the value relation to make safe type
changes. Finally, the message relation connects compatible messages such that
all instances of the original message can be parsed into instances of the updated
message.

\subsection{Value Relation}~\label{sec:val-rel}

The value relation is the base level of the compatibility relations, relating
just two individual values. Protobuf values are modeled here as a specification
level type in Rocq associated with a protobuf type as listed in
Table~\ref{tab:val-spec}. Finally, while protobuf decorators are technically
part of the field level specification, they have been incorporated into the type
information to allow the specification type into include \texttt{option} or
\texttt{list} Rocq types.

\begin{table}[H]
	\centering
	\begin{tabular}{cl}
      \toprule
      Specification Type & Protobuf Type \\
      \midrule
      $\mathbb{Z}$ & \ints, \uints, \sints,
            \intl, \uintl, \sintl{} \\
      $\mathbb{B}$ & \bool{}    \\
      \str{} & \str{}    \\
      \texttt{list w8}  & \byt{}    \\
      -- & \texttt{float}, \texttt{double} \\
      \bottomrule
	\end{tabular}

	\vspace{4mm}
	\caption[]{Description of the Rocq type corresponding to each protobuf
      type. Since Rocq has poor floating point number support, we've elected to
      omit those from consideration.}\label{tab:val-spec}
\end{table}

\begin{definition}[Value Relation]
  A protobuf value at the specification level $v_1$ with protobuf type $\tau_1$ is
  related to another value $v_2$ at type $\tau_2$, denoted $v_1 : \tau_1 \prec v_2 : \tau_2$
  if $parse_{\tau_2}\ serialize_{\tau_1}\ v_1 = v_2$.
\end{definition}

\subsubsection{Basic Rules}

The value relation is reflexive and transitive.

\begin{mathpar}
  \infer[Refl]{ }{v:\tau \prec v:\tau}

  \infer[Trans]{v_1:\tau_1 \prec v_2:\tau_2 \\ v_2:\tau_2 \prec v_3:\tau_3}{v_1:\tau_1 \prec v_3:\tau_3}
\end{mathpar}

\subsubsection{String \& Byte Rules}

It is possible to convert been the \texttt{string} and \texttt{bytes} types,
although the host program may have to deal with control character bytes being
present in the resulting string.

\begin{mathpar}
  \infer[Str-Byte]{ }{v: \str{} \prec{} v: \byt{}}

  \infer[Byte-Str]{ }{v: \byt{} \prec{} v: \str{}}
\end{mathpar}

\subsubsection{Integer Rules}

As a shorthand, statements like \uintn{n} represent a variable length integer
encoding into $n$ bits. In order to result in valid protobuf types,
$n \in \{32, 64\}$. The change width rules are designed to allow for both integer
promotion and demotion while the rest of the rules express what happens when
converting between integers using different encoding types for negative numbers.

With regard to the \textsc{Int-Chg-W} rule, I was originally concerned about
negative 32 bit numbers being encoded into 5 bytes for a varint encoding and
then becoming positive if parsed into 64 bit integer, but protobuf handles this
by writing all negative \intn{n} into a full 10 bytes. 

It is also worth noting that the expression $v : \tau$ actually refers to a value
of type $\denote{\tau}$ with a label of the type. All of the integer
types have $\denote{\cdot} = \mathbb{Z}$, as shown in Table~\ref{tab:val-spec},
which allows for the free conversion between integer types. Finally, $\%$ refers
to modulus using floored division, so $-1 \mod 2 = 1$ and the rules are
written with truncated integer division.

\begin{mathpar}
  \infer[Uint-Chg-W]{v_2 = v_1 \mod 2^m}{v_1: \uintn{n} \prec v_2: \uintn{m}}

  \infer[Int-Chg-W]{v_2 = (v_1 \mod 2^{m-1} - 2^{m-1}) \times \mathbb{1}[v_1 < 0]}
  {v_1 : \intn{n} \prec v_2 : \intn{m}}

  \infer[Sint-Chg-W]{v_2 = v_1 \mod 2^{m-1} - 2^{m-1} \times
    \mathbb{1}\left[\frac{v_1}{2^{m-1}} \mod 2 = 1\right]}{v_1 :
    \sintn{n} \prec v_2 : \sintn[m]}

  \infer[Uint-Int]{v_2 = v_1 - 2^n \times \mathbb{1}[v_1 \ge 2^{n-1}]}{v_1 :
    \uintn{n} \prec v_2 : \intn{n}}

  \infer[Int-Uint]{v_2 = v_1 + 2^n \times \mathbb{1}[v_1 < 0]}{v_1 :
    \intn{n} \prec v_2 : \uintn{n}} 

  \infer[Uint-Sint]{v_2 = (-1)^{v_1} \times \left( \frac{v_1}{2} \right) - (v_1 \%
    2)}{v_1 : \uintn{n} \prec v_2 : \sintn{n}} 

  \infer[Sint-Uint]{v_2 = 2 \times |v_1| - \mathbb{1}[v_1 < 0]}{v_1 :
    \sintn{n} \prec v_2 : \uintn{n}} 

  \infer[Int-Sint]
  {
    v_2 = \left\{
      {\begin{array}{l@{\quad:\quad}l}
        (-1)^{v_1} \times \left( \frac{v_1}{2} \right) - (v_1 \mod 2) & \text{if } v_1 \ge 0 \\
        (-1)^{v_1} \times \left(v_1 + 2^{n-1} - \frac{v_1}{2} \right) & \text{otherwise}
      \end{array}}\right.
  }
  {v_1 : \intn{n} \prec v_2 : \sintn{n}}

  \infer[Sint-Int]
  {
    v_2 = \left\{
      {\begin{array}{l@{\quad:\quad}l}
        2 \times |v_1| - \mathbb{1}[v_1 < 0] & \text{if } -2^{n-2} \le v_1 < 2^{n-2} \\
        2 \times |v_1| - 2^n - \mathbb{1}[v_1 < 0] & \text{otherwise}
      \end{array}}\right.
  }
  {v_1 : \sintn{n} \prec v_2 : \intn{n}}
\end{mathpar}

\subsubsection{Boolean Rules}

Booleans can be converted to and from any of the integer types.

\begin{mathpar}
  \infer[Uint-Bool]
  {
    v_2 = \left\{
      {\begin{array}{l@{\quad:\quad}l}
        \false & \text{if } v_1 = 0 \\
        \true & \text{otherwise}
      \end{array}}\right.
  }
  {v_1 : \uintn{n} \prec v_2 : \bool}

  \infer[Bool-Uint]{v_2 = \mathbb{1}[v_1]}{v_1 : \bool \prec v_2 :
    \uintn{n}} 

  \infer[Int-Bool]
  {
    v_2 = \left\{
      {\begin{array}{l@{\quad:\quad}l}
        \false & \text{if } v_1 = 0 \\
        \true & \text{otherwise}
      \end{array}}\right.
  }
  {v_1 : \intn{n} \prec v_2 : \bool}

  \infer[Bool-Int]{v_2 = \mathbb{1}[v_1]}{v_1 : \bool \prec v_2 :
    \intn{n}} 

  \infer[Sint-Bool]
  {
    v_2 = \left\{
      {\begin{array}{l@{\quad:\quad}l}
        \false & \text{if } v_1 = 0 \\
        \true & \text{otherwise}
      \end{array}}\right.
  }
  {v_1 : \sintn{n} \prec v_2 : \bool}

  \infer[Bool-Sint]{v_2 = -\mathbb{1}[v_1]}{v_1 : \bool \prec v_2 :
    \sintn{n}} 
\end{mathpar}

\subsubsection{Message \& Enum Rules}

Definitions for the structure of a message and enum are given in
Section~\ref{sec:msg-rel}. The values are represented as a mapping from the id
number of each field to the value and type of that field. 

\begin{mathpar}
  \infer[Msg]{\msg{r_1}{f_1} \preceq \msg{r_2}{f_2} \\ \forall\;i \in \dom{v_2}.\;\left( f_1(i) =
      (s, \tau_1) \wedge v_1(i) \prec v_2(i) \right) \vee v_2(i) = default\left(\mathtt{snd}\ f_2(i)\right)}
  {v_1 : \mathtt{MSG}\ \msg{r_1}{f_1} \prec v_2 : \mathtt{MSG}\ \msg{r_2}{f_2} }
  
  \infer[Enum]{v \in e_2}{v : \enum{e_1} \prec v : \enum{e_2}}
\end{mathpar}

\subsubsection{Decorator Rules}

Since the specification type can include \texttt{option}'s and \texttt{list}'s,
rules for handling these must also be present in the value relation. These rules
are grouped into introduction rules, which take implicit values and make them
optional or repeated, pass through rules which enable the above rules to operate
on these modified types.

{\color{red} There really should be a rule which can introduce a \texttt{None},
  but since implicit fields are modeled as just the spec type, this is
  difficult. I will likely need to model both implicit and optional fields with
  an \texttt{option}, add an annotation to the protobuf type and provide a
  function which introduces a default value for each type.}

\begin{mathpar}
  \infer[Rep-Pass]{v_1:\tau_1 \prec v_1':\tau_2 \\ \cdots \\ v_n:\tau_1 \prec v_n':\tau_2}{[v_1; \dots;
    v_n]: \rept{\tau_1} \prec [v_1'; \dots; v_n']: \rept{\tau_2}}

  \infer[Opt-Some-Pass]{v_1:\tau_1 \prec v_2:\tau_2}{(\some{v_1}): \optt{\tau_1} \prec
    (\some{v_2}): \optt{\tau_2}}

  \infer[Opt-None-Pass]{ }{\none: \optt{\tau_1} \prec \none: \optt{\tau_2}}
  
  \infer[Opt-Intro]{ }{v:\tau \prec (\some{v}): \optt{\tau}}

  \infer[Rep-Intro]{ }{v:\tau \prec [v]: \rept{\tau}}

  \infer[Missing-Imp]{ }{\none: \tau_1 \prec default(\tau_2):\tau_2}
\end{mathpar}

\subsection{Type Relation}~\label{sec:typ-rel}

This relation relates types which can be converted via the value relation.
\\
\begin{definition}[Type Relation]
  The type relation relates two protobuf type $\tau_1$ and $\tau_2$, denoted $\tau_1 \propto
  \tau_2$ if for all $v_1:\tau_1$ there exists a $v_2:\tau_2$ such that $v_1:\tau_1 \prec v_2:\tau_2$.
\end{definition}

\subsubsection{Base Type Rules}

\begin{mathpar}
  \infer[Str-Byt-T]{ }{\str \propto \byt}

  \infer[Byt-Str-T]{ }{\byt \propto \str}

  \infer[Int-Int-T]{\tau_1, \tau_2 \in \left\{{
        \begin{array}{c}
          \ints, \intl, \uints, \uintl \\
          \sints, \sintl, \bool
        \end{array}
      }\right\}}{\tau_1 \propto \tau_2}
\end{mathpar}

\subsubsection{Message \& Enum Rules}

\begin{mathpar}
  \infer[Msg-T]{m_1 \preceq m_2}{\mathtt{MSG}\ m_1 \propto \mathtt{MSG}\ m_2}

  \infer[Enum-T]{e_1 \subset e_2}{\enum{e_1} \propto \enum{e_2}}
\end{mathpar}

\subsubsection{Decorator Rules}

Since the type relation is designed for checking for safe type changes, it also
need to ensure that decorator restrictions like moving from a repeated field to
a singleton one aren't violated.

\begin{mathpar}
  \infer[Opt-Add-T]{ }{\tau \propto \optt{\tau}}

  \infer[Opt-Rm-T]{ }{\optt{\tau} \propto \tau}

  \infer[Opt-T]{\tau_1 \propto \tau_2}{\optt{\tau_1} \propto \optt{\tau_2}}

  \infer[Rep-Add-T]{ }{\tau \propto \rept{\tau}}

  \infer[Rep-T]{\tau_1 \propto \tau_2}{\rept{\tau_1} \propto \rept{\tau_2}}
\end{mathpar}

\subsection{Message Relation}~\label{sec:msg-rel}

The descriptor compatibility relation $\preceq$ is defined as below, but first it is
important to discuss the structure of fields and messages.

A message value is a tuple containing a set of reserved field numbers and names,
then a map from an identifier to a tuple with the name of the field and the type
of the field. The identifier is either a tag for a single field, or a set of
integers which is used for a \texttt{oneof}, where multiple fields must be
mutually exclusively set.

Enums will be modeled as a set of integers, likewise ignoring the name given to
each element to favor the integer which is used in the encoding. 

\subsubsection{Basic Rules}

A compatibility relation is both reflexive and transitive, although it is
neither symmetric nor anti-symmetric.  

\begin{mathpar}
   \infer[Refl-M]{ }{m \preceq m}

   \infer[Refl-E]{ }{e \preceq e}

   \infer[Trans-M]{m_1 \preceq m_2 \\ m_2 \preceq m_3}{m_1 \preceq m_3}

   \infer[Trans-E]{e_1 \preceq e_2 \\ e_2 \preceq e_3}{e_1 \preceq e_3}
\end{mathpar}

\subsubsection{Field Update Rules}

For the moment, names are recorded the protobuf field descriptors for accuracy
and to allow the relations to expand in the future. However, since names are
recorded in the encoded message, they are currently allowed to freely change.

\begin{mathpar}
  \infer[Field-Type]{f(id) = \tau_1 \\ \tau_1 \propto \tau_2}{\msg{r}{f} \preceq \msg{r}{f[id \mapsto \tau_2]}}

  \infer[Field-Add]{id \not \in \textrm{dom}(f) }{\msg{r}{f} \preceq \msg{r}{f[id \mapsto \tau]}}

  % TODO: May need restrictions about maps in maps...
  \infer[Map-Type-F]{f(id) = (\map{\tau_1}{\impt{\tau_2})} \\ \tau_1 \propto \tau_1' \\ \tau_2 \propto \impt{\tau_2'} \\ \tau_1 \ne \byt}
  {\msg{r}{f} \preceq \msg{r}{f[id \mapsto (\map{\tau_1'}{\imp{\tau_2'}})]}}
\end{mathpar}

\subsubsection{Oneof Rules}

The \texttt{oneof} rules are a bit complicated because a \texttt{oneof}
struggles against the notion that the field relations only connects one field to
one field by encapsulating several fields into a singular field.

% FIXME: Oneof fields don't cleanly fit into the map abstractions since there is
% no clear choice of key.

\begin{mathpar}
  \infer[Oneof-Intro-Field]{d \in \{\imp, \opt\} \\ f(id) = d\ \tau}
  {\msg{r}{f} \preceq \msg{r}{f[\{id\} \mapsto \oneof{id \mapsto (d\ \tau)}]}}

  % May need some statement about f_{n+1} not already being in the message?
  % You can introduce a new field, but not move an existing one.
  \infer[Oneof-Add-F]{d \in \{\mathtt{IMP}, \mathtt{OPT}\} \\ id_n \not \in
    id_s \\ f(id_s) = m \\ id_n \not \in  \mathrm{dom}(m) \\ \tau \not= \mathtt{MAP}}
  {\msg{r}{f} \preceq \msg{r}{f[id_s \cup \{id_n\} \mapsto (m[id_n \mapsto (d \tau)])]}}

  % This rule should just be a combination of the above two rules...
  \infer[Oneof-Intro-New]{\dom{ f } \cap \dom{ f_o } = \emptyset
    \\ \mathtt{REP} \not \in dec(f_o) \\ \forall\;id_n \in \dom{f_o}.\
    \texttt{snd}\ f_o(id_n) \ne \mathtt{MAP}}{\msg{r}{f} \preceq \msg{r}{f[\dom{f_o}
      \mapsto f_o]}}

  \infer[Oneof-Elim]{f(id_n) = m \\ id \in id_n }
  {\msg{r}{f} \preceq \msg{r}{f[id_n \setminus id \mapsto m \setminus id]}}

  % I'm not sure about the premise of this rule, but it seems better than having
  % to making another version of all the other rules. This is the first instance
  % where having a field relation would be very helpful.
  \infer[Oneof-Feild-Update]{f_o(id) = \tau \\ \tau' \propto \tau}
  {\msg{r}{f[id \mapsto f_o]} \preceq \msg{r}{f[id \mapsto ( f_o[id \mapsto \tau'] )]}}
\end{mathpar}

\subsubsection{Field \& Enum Rules}

Messages are similar to records in Rocq or other functional languages and
message compatibility can take the same two routes that record subtyping can:
width compatibility and depth compatibility. In width compatibility updates, new
fields are added to the message, making the updated version a strict superset of
the original message. In depth compatibility updates, the number of fields
remains the same, but other attributes of the field are updated compatible ways.

\begin{mathpar}
  \infer[Msg-Width-Field]{id \not \in \mathrm{dom}(f)}
  {\msg{r}{f} \preceq \msg{r}{f[id \mapsto \tau]}}

  \infer[Msg-Width-Depth]{f(id) = \tau \\ \tau' \propto \tau}
  {\msg{r}{f} \preceq \msg{r}{f[id \mapsto \tau']}}
\end{mathpar}

The enum rules are similar to the message rules at least in the sense that enums
can be updated to have new fields without issue. However, when considering
removing fields from an enum definition, it is important to know if the enum is
treated as open or closed~\cite{EnumBehavior}. By default, \texttt{proto3}
treats all enums as open, so it should be possible to write a rule allowing for
the deletion of an enum field. This naturally aligns with how \texttt{go}
handles enums, since it doesn't support closed enums. Since protobuf enums don't
contain extra information, no depth rules is allowed.

\begin{mathpar}
  \infer[Enum-Width]{vals(e_1) \subset vals(e_2)}{e_1 \preceq e_2}
\end{mathpar}

\subsubsection{Reserved Field Rules}

\begin{mathpar}
  \infer[Reserved-Add]{r \subset r'}{\msg{r}{f} \preceq \msg{r'}{f}}

  {\color{red}
    \infer[Reserved-Rm]{r \supset r'}{\msg{r}{f} \preceq \msg{r'}{f}}
  }
\end{mathpar}

\subsubsection{Valid Descriptors}

\begin{definition}[Valid Protobuf Descriptors]
  A protobuf message descriptor is \emph{valid}, denoted $v(d)$ if
  $\msg{\emptyset}{\emptyset} \preceq \msg{r}{f}$.
\end{definition}

\subsubsection{Compatibility Theorem}

The main field-level compatibility theorem is stated below.
\\
\begin{theorem}[Field Compatibility]
  If $d_1 \preceq d_2$ then for all binary strings $bs$ such that
  $\mathtt{parse}_{d_1}\ bs = \mathtt{Some}\ v_1$, $\mathtt{parse}_{d_2}\ bs =
  \mathtt{Some}\ v_2$ and $v_1 \prec v_2$
\end{theorem}

\section{Compatibility Relation Examples}

Consider these two Protobuf descriptors

\begin{figure}[H]
	\centering
	\begin{minipage}[bt]{0.43\textwidth}
		\begin{lstlisting}[language=proto]
// v1.proto -- A base proto for the
// example software. Tracks some
// basic information about an item,
// with the ledger itself basically
// being a list of items.
syntax = "proto3";

message Location {
  string loc = 2;
}

message Item {
  string name = 2;
  string description = 3;
  int32 value = 4;
  Location loc = 5;
}

message Ledger {
  int32 version = 1;
  string world_name = 2;
  repeated Item log = 3;
}\end{lstlisting}
	\end{minipage}
	\hspace{0.5cm}
	\begin{minipage}[bt]{0.48\textwidth}
		\begin{lstlisting}[language=proto]
// v2.proto -- build off v1.proto by
// adding some extra fields to the
// item, such as item level, and
// split descriptions and locations
syntax = "proto3";

message Location {
  string loc = 2;
}

message Item {
  string name = 2;
  string public_description = 3;
  string private_description = 7;
  int64 value = 4;
  int32 level = 6;
  Location origin_loc = 5;
  Location current_loc = 8;
}

message Ledger {
  int32 version = 1;
  string world_name = 2;
  repeated Item log = 3;
}\end{lstlisting}
	\end{minipage}

	\caption{Example Protobuf descriptors for a hypothetical piece of software
      which tracks TTRPG items, showing the original version on the left and an
      updated version on the right.}
	\label{fig:proto-ex}
\end{figure}

Clearly these descriptors are different, but are they \emph{compatible}?
Evidence of their compatibility is a derivation of the compatibility relation.
First, use the Message Relation (Section~\ref{sec:msg-rel}) to show that the base
descriptors are compatible. Since the \texttt{Location} and \texttt{Ledger}
messages are the same, one application of the reflexivity rule shows these to be
compatible. Focus on the \texttt{item} message then. 
\begin{align*}
  &\msg{\emptyset}{f} \\
  &\left\{f(3) = (\lb{description}, \str) \right\} \\
  &\msg{\emptyset}{f[3 \mapsto \field{public\_description}{\str}]} = \msg{\emptyset}{f_1} \\
  &\left\{ \ints \propto \intl \right\} \\
  &\msg{\emptyset}{f_1[4 \mapsto \field{value}{\intl}]} = \msg{\emptyset}{f_2} \\
  &\left\{ f_2(5) = \field{loc}{\mathtt{Location}} \right\} \\
  &\msg{\emptyset}{f_2[5 \mapsto \field{current\_loc}{\mathtt{Location}}]} = \msg{\emptyset}{f_3} \\
  &\left\{ 6 \not \in \dom{f_3} \right\} \\
  &\msg{\emptyset}{f_3[6 \mapsto \field{level}{\ints}]} = \msg{\emptyset}{f_4} \\
  &\left\{ 7 \not \in \dom{f_4} \right\} \\
  &\msg{\emptyset}{f_4[7 \mapsto \field{private\_description}{\str}]} = \msg{\emptyset}{f_5} \\
  &\left\{ 8 \not \in \dom{f_5} \right\} \\
  &\msg{\emptyset}{f_5[8 \mapsto \field{current\_loc}{\mathtt{Location}}]}
\end{align*}

If we had concrete values for these descriptors, it would also be possible to
show that those two values were related using the value relation.

% Local Variables:
% citar-bibliography: ("../pollux.bib")
% TeX-master: "../pollux.tex"
% jinx-local-words: "protobuf"
% End:
